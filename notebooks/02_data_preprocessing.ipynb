{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# CO2 Emission Data Preprocessing\n", "In this notebook, we will preprocess the CO2 emissions dataset to prepare it for machine learning modeling. This involves handling missing data, scaling the features, and splitting the data for training and testing."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import necessary libraries\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load the Cleaned Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the cleaned dataset\n", "data_path = 'path_to_cleaned_file/co2_emissions_cleaned.csv'\n", "df = pd.read_csv(data_path)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Handle Missing Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fill or drop missing values\n", "df.fillna(method='ffill', inplace=True)  # Forward fill to handle missing values\n", "# You can also choose to drop rows or columns with too many missing values if necessary\n", "# df.dropna(inplace=True)\n", "df.isnull().sum()  # Check for remaining missing values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Feature Scaling"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Scale the features using StandardScaler\n", "scaler = StandardScaler()\n", "scaled_features = scaler.fit_transform(df.iloc[:, 4:])  # Scale the year columns (numeric)\n", "scaled_df = pd.DataFrame(scaled_features, columns=df.columns[4:])\n", "scaled_df.insert(0, 'Country Name', df['Country Name'])  # Add back the non-scaled columns\n", "scaled_df.insert(1, 'Country Code', df['Country Code'])\n", "scaled_df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Splitting the Data for Training and Testing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define X (features) and y (target) for ML\n", "X = scaled_df.iloc[:, 2:]  # All numeric columns (scaled)\n", "y = df.iloc[:, 3]  # Example: You may want to predict emissions for the latest year available\n", "\n", "# Split the data into training and test sets\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "X_train.shape, X_test.shape, y_train.shape, y_test.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Next Steps\n", "- After preprocessing, the data is ready for modeling.\n", "- You can now use this preprocessed data in your machine learning models (e.g., regression, time-series forecasting)."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}